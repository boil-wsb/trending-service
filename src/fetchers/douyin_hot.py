"""
æŠ–éŸ³çƒ­æ¦œè·å–å™¨
ä½¿ç”¨ Playwright ç›´æ¥ä»æŠ–éŸ³ç½‘é¡µè·å–çƒ­æ¦œæ•°æ®
"""

import sys
import re
import time
from typing import List, Dict, Optional
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.config import DATA_SOURCES, REQUESTS
from src.utils import get_logger
from .base import BaseFetcher, TrendingItem

# å°è¯•å¯¼å…¥ Playwright
try:
    from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeout
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False


class DouyinHotFetcher(BaseFetcher):
    """æŠ–éŸ³çƒ­æ¦œè·å–å™¨ï¼ˆä½¿ç”¨ Playwright æ— å¤´æµè§ˆå™¨ï¼‰"""

    name = "douyin"
    HOT_URL = "https://www.douyin.com/hot"

    def __init__(self, config: Dict = None, logger=None):
        super().__init__(config, logger)
        self.logger = logger or get_logger(self.name)
        self.config = config or DATA_SOURCES.get(self.name, {'limit': 50})

    def fetch(self) -> List[TrendingItem]:
        """
        è·å–æŠ–éŸ³çƒ­æ¦œ

        Returns:
            List[TrendingItem]: çƒ­ç‚¹æ•°æ®åˆ—è¡¨
        """
        if not PLAYWRIGHT_AVAILABLE:
            self.logger.error("Playwright æœªå®‰è£…ï¼Œæ— æ³•è·å–æŠ–éŸ³çƒ­æ¦œ")
            return []

        self.logger.info("å¼€å§‹è·å–æŠ–éŸ³çƒ­æ¦œ...")

        items = []
        try:
            with sync_playwright() as p:
                # å¯åŠ¨æµè§ˆå™¨
                browser = p.chromium.launch(headless=True)

                # åˆ›å»ºä¸Šä¸‹æ–‡
                context = browser.new_context(
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    viewport={'width': 1920, 'height': 1080},
                    locale='zh-CN',
                )

                # åˆ›å»ºé¡µé¢
                page = context.new_page()

                # è®¿é—®æŠ–éŸ³çƒ­æ¦œ
                self.logger.info(f"è®¿é—®: {self.HOT_URL}")
                page.goto(self.HOT_URL, wait_until='domcontentloaded', timeout=30000)

                # ç­‰å¾…é¡µé¢åŠ è½½
                time.sleep(5)

                # è§£æçƒ­æ¦œæ•°æ®
                items = self._parse_hot_list(page)

                # å…³é—­æµè§ˆå™¨
                browser.close()

                self.logger.info(f"æŠ–éŸ³çƒ­æ¦œ: è·å– {len(items)} æ¡æ•°æ®")

        except PlaywrightTimeout:
            self.logger.error("é¡µé¢åŠ è½½è¶…æ—¶")
        except Exception as e:
            self.logger.error(f"è·å–æŠ–éŸ³çƒ­æ¦œå¤±è´¥: {e}")

        return items

    def _parse_hot_list(self, page) -> List[TrendingItem]:
        """è§£ææŠ–éŸ³çƒ­æ¦œé¡µé¢"""
        items = []

        try:
            # å°è¯•ä½¿ç”¨é€‰æ‹©å™¨è·å–æ›´ç»“æ„åŒ–çš„æ•°æ®
            hot_cards = page.query_selector_all('[data-e2e="hot-list-item"], .hot-list-item, [class*="hot"] [class*="item"], .list-item')
            
            if hot_cards and len(hot_cards) > 0:
                # ä½¿ç”¨ç»“æ„åŒ–è§£æ
                items = self._parse_structured_cards(hot_cards)
            else:
                # å›é€€åˆ°æ–‡æœ¬è§£æ
                items = self._parse_text_based(page)

            # é™åˆ¶æ•°é‡
            limit = self.config.get('limit', 50)
            items = items[:limit]

        except Exception as e:
            self.logger.error(f"è§£æçƒ­æ¦œé¡µé¢å¤±è´¥: {e}")
            # å°è¯•æ–‡æœ¬è§£æä½œä¸ºåå¤‡
            try:
                items = self._parse_text_based(page)
            except Exception as e2:
                self.logger.error(f"æ–‡æœ¬è§£æä¹Ÿå¤±è´¥: {e2}")

        return items

    def _parse_structured_cards(self, cards) -> List[TrendingItem]:
        """è§£æç»“æ„åŒ–çš„çƒ­æ¦œå¡ç‰‡"""
        items = []
        
        for idx, card in enumerate(cards[:50], 1):  # æœ€å¤šå–50æ¡
            try:
                # å°è¯•æå–æ ‡é¢˜
                title_el = card.query_selector('[data-e2e="hot-title"], .title, h3, .content-text, [class*="title"]')
                title = title_el.inner_text().strip() if title_el else ""
                
                # å°è¯•æå–çƒ­åº¦
                hot_score = 0.0
                hot_text = "0"
                hot_el = card.query_selector('[data-e2e="hot-score"], .hot-score, [class*="hot"], [class*="heat"]')
                if hot_el:
                    hot_text_raw = hot_el.inner_text().strip()
                    match = re.search(r'(\d+(?:\.\d+)?)ä¸‡', hot_text_raw)
                    if match:
                        hot_score = float(match.group(1)) * 10000
                        hot_text = f"{match.group(1)}ä¸‡"
                
                # å°è¯•æå–åˆ›ä½œè€…/ä½œè€…
                author = None
                author_el = card.query_selector('[data-e2e="author"], .author, .creator, [class*="author"], [class*="user"], [class*="creator"]')
                if author_el:
                    author = author_el.inner_text().strip()
                
                if title and len(title) > 3:
                    search_query = title.replace(' ', '').replace('#', '')
                    url = f"https://www.douyin.com/search/{search_query}"
                    
                    item = TrendingItem(
                        source=self.name,
                        title=title,
                        url=url,
                        author=author,
                        description=None,
                        hot_score=hot_score,
                        category='hot',
                        extra={
                            'rank': idx,
                            'hot_text': hot_text,
                        }
                    )
                    if self.validate_item(item):
                        items.append(item)
                        
            except Exception as e:
                self.logger.warning(f"è§£æå¡ç‰‡å¤±è´¥: {e}")
                continue
        
        return items

    def _parse_text_based(self, page) -> List[TrendingItem]:
        """åŸºäºæ–‡æœ¬çš„è§£æï¼ˆåå¤‡æ–¹æ¡ˆï¼‰"""
        items = []
        text = page.inner_text('body')
        lines = text.split('\n')

        hot_items = []
        i = 0
        while i < len(lines):
            line = lines[i].strip()

            # å°è¯•åŒ¹é…æ’åï¼ˆæ•°å­—ï¼‰
            if line.isdigit() and 1 <= int(line) <= 100:
                rank = int(line)

                # ä¸‹ä¸€è¡Œæ˜¯æ ‡é¢˜
                if i + 1 < len(lines):
                    title = lines[i + 1].strip()

                    # å†ä¸‹ä¸€è¡Œå¯èƒ½æ˜¯çƒ­åº¦
                    hot_score = 0.0
                    hot_text = "0"
                    author = None
                    
                    if i + 2 < len(lines):
                        hot_line = lines[i + 2].strip()
                        # åŒ¹é…çƒ­åº¦æ ¼å¼: "1207.1ä¸‡çƒ­åº¦" æˆ– "1207.1ä¸‡"
                        match = re.search(r'(\d+(?:\.\d+)?)ä¸‡', hot_line)
                        if match:
                            hot_score = float(match.group(1)) * 10000
                            hot_text = f"{match.group(1)}ä¸‡"
                            i += 1  # è·³è¿‡çƒ­åº¦è¡Œ
                        
                        # å°è¯•æŸ¥æ‰¾åˆ›ä½œè€…ï¼ˆé€šå¸¸åœ¨çƒ­åº¦ä¹‹åï¼‰
                        # æ³¨æ„ï¼šæŠ–éŸ³çƒ­æ¦œé€šå¸¸ä¸æ˜¾ç¤ºåˆ›ä½œè€…ä¿¡æ¯ï¼Œè¿™é‡Œä»…åœ¨æœ‰æ˜ç¡®æ ‡è¯†æ—¶æ‰æå–
                        # åˆ›ä½œè€…é€šå¸¸æœ‰ç‰¹å®šçš„å‰ç¼€æˆ–æ ‡è¯†ï¼Œå¦‚ "@ç”¨æˆ·å" æˆ– "åˆ›ä½œè€…ï¼šxxx"
                        if i + 3 < len(lines):
                            next_line = lines[i + 3].strip()
                            # ä¸¥æ ¼åˆ¤æ–­ï¼šåªæœ‰ç¬¦åˆåˆ›ä½œè€…ç‰¹å¾çš„è¡Œæ‰è®¤ä¸ºæ˜¯åˆ›ä½œè€…
                            # åˆ›ä½œè€…ç‰¹å¾ï¼šä»¥ @ å¼€å¤´ï¼Œæˆ–åŒ…å« "åˆ›ä½œè€…"ã€"ä½œè€…" ç­‰å…³é”®è¯
                            is_author = (
                                next_line.startswith('@') or
                                'åˆ›ä½œè€…' in next_line or
                                'ä½œè€…' in next_line or
                                'å‘å¸ƒè€…' in next_line
                            )
                            # åŒæ—¶æ’é™¤æ˜æ˜¾ä¸æ˜¯åˆ›ä½œè€…çš„æƒ…å†µï¼ˆå¦‚å¦ä¸€ä¸ªæ ‡é¢˜ï¼‰
                            is_likely_title = (
                                len(next_line) > 15 or  # æ ‡é¢˜é€šå¸¸è¾ƒé•¿
                                'å¤§å¸ˆèµ›' in next_line or  # å¸¸è§æ ‡é¢˜å…³é”®è¯
                                'å† å†›' in next_line or
                                'æ¯”èµ›' in next_line or
                                'å†³èµ›' in next_line
                            )
                            if is_author and not is_likely_title:
                                author = next_line
                                i += 1

                    # è¿‡æ»¤æ— æ•ˆæ ‡é¢˜
                    if title and len(title) > 3 and not title.startswith('çƒ­åº¦'):
                        hot_items.append({
                            'rank': rank,
                            'title': title,
                            'hot_score': hot_score,
                            'hot_text': hot_text,
                            'author': author
                        })
                    i += 1
            i += 1

        # è½¬æ¢ä¸º TrendingItem
        for item_data in hot_items:
            try:
                search_query = item_data['title'].replace(' ', '').replace('#', '')
                url = f"https://www.douyin.com/search/{search_query}"

                item = TrendingItem(
                    source=self.name,
                    title=item_data['title'],
                    url=url,
                    author=item_data.get('author'),
                    description=None,
                    hot_score=item_data['hot_score'],
                    category='hot',
                    extra={
                        'rank': item_data['rank'],
                        'hot_text': item_data['hot_text'],
                    }
                )
                if self.validate_item(item):
                    items.append(item)
            except Exception as e:
                self.logger.warning(f"è§£ææ¡ç›®å¤±è´¥: {e}")
                continue

        return items


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è·å–æŠ–éŸ³çƒ­æ¦œ...")

    fetcher = DouyinHotFetcher()
    items = fetcher.fetch()

    print(f"\nâœ… è·å–æˆåŠŸ: {len(items)} æ¡æ•°æ®")
    print("\nå‰10æ¡æ•°æ®:")
    for i, item in enumerate(items[:10], 1):
        rank = item.extra.get('rank', '-')
        hot_text = item.extra.get('hot_text', '')
        print(f"{i}. [{rank}] {item.title[:50]}...")
        print(f"   çƒ­åº¦: {hot_text}")
        print(f"   é“¾æ¥: {item.url[:60]}...")
        print()


if __name__ == "__main__":
    main()
