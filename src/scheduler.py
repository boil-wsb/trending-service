"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨æ¨¡å—
ç®¡ç†å®šæ—¶ä»»åŠ¡çš„æ‰§è¡Œ
"""

import time
import webbrowser
import socket
import requests
from threading import Thread, Event
from datetime import datetime
from typing import Callable, Dict, List, Optional
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼ˆæ”¯æŒç›´æ¥è¿è¡Œå’Œä½œä¸ºåŒ…å¯¼å…¥ï¼‰
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.config import SCHEDULE, DATA_SOURCES, REPORTS_DIR, BROWSER, SERVER, DATABASE
from src.utils import get_logger, ReportGenerator
from src.utils.retry_manager import RetryManager, FetchResult, FetchStatus, RetryConfig
from src.db import TrendingDAO, FetchFailureDAO
from src.fetchers import (
    GitHubTrendingFetcher, 
    BilibiliHotFetcher, 
    ArxivPapersFetcher,
    HackerNewsFetcher,
    ZhihuHotFetcher,
    WeiboHotFetcher,
    DouyinHotFetcher
)
from src.analytics import extract_keywords_for_items


class TaskScheduler:
    """å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨"""

    def __init__(self, logger=None):
        self.logger = logger or get_logger('scheduler')
        self.tasks: Dict[str, Dict] = {}
        self.running = False
        self.stop_event = Event()
        self.scheduler_thread = None

    def add_task(self, name: str, schedule: str, task_func: Callable, enabled: bool = True):
        """
        æ·»åŠ å®šæ—¶ä»»åŠ¡

        Args:
            name: ä»»åŠ¡åç§°
            schedule: cronè¡¨è¾¾å¼ (ç®€åŒ–ç‰ˆ: "HH:MM" æˆ– "H * * * *")
            task_func: ä»»åŠ¡å‡½æ•°
            enabled: æ˜¯å¦å¯ç”¨
        """
        self.tasks[name] = {
            'schedule': schedule,
            'func': task_func,
            'enabled': enabled,
            'last_run': None
        }
        self.logger.info(f"æ·»åŠ ä»»åŠ¡: {name} (schedule: {schedule})")

    def remove_task(self, name: str):
        """ç§»é™¤å®šæ—¶ä»»åŠ¡"""
        if name in self.tasks:
            del self.tasks[name]
            self.logger.info(f"ç§»é™¤ä»»åŠ¡: {name}")

    def enable_task(self, name: str, enabled: bool = True):
        """å¯ç”¨/ç¦ç”¨ä»»åŠ¡"""
        if name in self.tasks:
            self.tasks[name]['enabled'] = enabled
            self.logger.info(f"ä»»åŠ¡ {name} {'å¯ç”¨' if enabled else 'ç¦ç”¨'}")

    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.running:
            self.logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œä¸­")
            return

        self.running = True
        self.stop_event.clear()
        self.scheduler_thread = Thread(target=self._run_scheduler, daemon=True)
        self.scheduler_thread.start()
        self.logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")

    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        if not self.running:
            return

        self.running = False
        self.stop_event.set()

        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=5)

        self.logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")

    def _run_scheduler(self):
        """è°ƒåº¦å™¨ä¸»å¾ªç¯"""
        self.logger.info("è°ƒåº¦å™¨å¼€å§‹è¿è¡Œ...")

        while self.running and not self.stop_event.is_set():
            try:
                # æ£€æŸ¥æ¯ä¸ªä»»åŠ¡
                for name, task in self.tasks.items():
                    if not task['enabled']:
                        continue

                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œ
                    if self._should_run(task):
                        self.logger.info(f"æ‰§è¡Œä»»åŠ¡: {name}")
                        try:
                            task['func']()
                            task['last_run'] = datetime.now()
                        except Exception as e:
                            self.logger.error(f"ä»»åŠ¡ {name} æ‰§è¡Œå¤±è´¥: {e}")

                # ç­‰å¾…ä¸€æ®µæ—¶é—´å†æ£€æŸ¥
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

            except Exception as e:
                self.logger.error(f"è°ƒåº¦å™¨è¿è¡Œé”™è¯¯: {e}")
                time.sleep(60)

        self.logger.info("è°ƒåº¦å™¨å·²åœæ­¢")

    def _should_run(self, task: Dict) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦åº”è¯¥æ‰§è¡Œ"""
        schedule = task['schedule']
        last_run = task['last_run']

        # ç®€åŒ–ç‰ˆcronè§£æï¼šæ”¯æŒ "HH:MM" æ ¼å¼
        if ':' in schedule:
            try:
                now = datetime.now()
                target_time = datetime.strptime(schedule, "%H:%M").time()
                current_time = now.time()

                # æ£€æŸ¥æ˜¯å¦åˆ°äº†æ‰§è¡Œæ—¶é—´ä¸”ä»Šå¤©è¿˜æ²¡æ‰§è¡Œè¿‡
                if (current_time.hour == target_time.hour and
                    current_time.minute == target_time.minute):
                    if last_run is None or last_run.date() != now.date():
                        return True
            except:
                pass

        return False

    def run_task_now(self, name: str):
        """ç«‹å³æ‰§è¡ŒæŒ‡å®šä»»åŠ¡"""
        if name in self.tasks:
            self.logger.info(f"ç«‹å³æ‰§è¡Œä»»åŠ¡: {name}")
            try:
                self.tasks[name]['func']()
                self.tasks[name]['last_run'] = datetime.now()
            except Exception as e:
                self.logger.error(f"ä»»åŠ¡ {name} æ‰§è¡Œå¤±è´¥: {e}")


class TrendingTaskScheduler(TaskScheduler):
    """Trending Service å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨ï¼ˆé›†æˆé‡è¯•æœºåˆ¶ï¼‰"""

    def __init__(self, logger=None):
        # å…ˆè°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–è®¾ç½® logger
        super().__init__(logger)
        
        self.dao = TrendingDAO(DATABASE['path'])
        self.failure_dao = FetchFailureDAO(DATABASE['path'])
        
        # åˆå§‹åŒ–é‡è¯•ç®¡ç†å™¨
        retry_config = RetryConfig(
            max_retries=3,
            base_delay=60,
            max_delay=300,
            exponential_base=2.0
        )
        self.retry_manager = RetryManager(config=retry_config, logger=self.logger)
        
        # è®¾ç½®æŒä¹…åŒ–å›è°ƒ
        self.retry_manager.set_persist_callback(self._persist_fetch_result)
        
        # æ³¨å†Œæ•°æ®æºè·å–å‡½æ•°
        self._register_fetchers()
        
        self._setup_tasks()
        
        # åŠ è½½å¾…é‡è¯•çš„ä»»åŠ¡
        self._load_pending_retries()

    def _register_fetchers(self):
        """æ³¨å†Œæ‰€æœ‰æ•°æ®æºè·å–å‡½æ•°åˆ°é‡è¯•ç®¡ç†å™¨"""
        fetchers = {
            'github': lambda: GitHubTrendingFetcher(logger=self.logger).fetch(),
            'github_ai': lambda: GitHubTrendingFetcher(logger=self.logger).get_ai_repos(),
            'bilibili': lambda: BilibiliHotFetcher(logger=self.logger).fetch(),
            'arxiv': lambda: ArxivPapersFetcher(logger=self.logger).fetch(),
            'hackernews': lambda: HackerNewsFetcher(logger=self.logger).fetch(),
            'zhihu': lambda: ZhihuHotFetcher(logger=self.logger).fetch(),
            'weibo': lambda: WeiboHotFetcher(logger=self.logger).fetch(),
            'douyin': lambda: DouyinHotFetcher(logger=self.logger).fetch(),
        }
        
        for source, fetcher in fetchers.items():
            # github_ai æ˜¯ github çš„è¡ç”Ÿæ•°æ®æºï¼Œè·Ÿéš github çš„å¯ç”¨çŠ¶æ€
            if source == 'github_ai':
                if DATA_SOURCES.get('github', {}).get('enabled'):
                    self.retry_manager.register_fetcher(source, fetcher)
                    self.logger.debug(f"æ³¨å†Œæ•°æ®æº: {source}")
            elif DATA_SOURCES.get(source, {}).get('enabled'):
                self.retry_manager.register_fetcher(source, fetcher)
                self.logger.debug(f"æ³¨å†Œæ•°æ®æº: {source}")

    def _persist_fetch_result(self, result: FetchResult):
        """æŒä¹…åŒ–è·å–ç»“æœåˆ°æ•°æ®åº“"""
        try:
            if result.success:
                # å¦‚æœæˆåŠŸï¼Œæ ‡è®°ä¸ºæˆåŠŸ
                self.failure_dao.mark_success(result.source)
            else:
                # å¦‚æœå¤±è´¥ï¼Œä¿å­˜å¤±è´¥è®°å½•
                next_retry = None
                if result.retry_count < self.retry_manager.config.max_retries:
                    delay = self.retry_manager.config.calculate_delay(result.retry_count)
                    from datetime import timedelta
                    next_retry = datetime.now() + timedelta(seconds=delay)
                
                self.failure_dao.save_failure(
                    source=result.source,
                    error_message=result.error_message,
                    retry_count=result.retry_count,
                    next_retry_at=next_retry
                )
        except Exception as e:
            self.logger.error(f"æŒä¹…åŒ–è·å–ç»“æœå¤±è´¥: {e}")

    def _load_pending_retries(self):
        """ä»æ•°æ®åº“åŠ è½½å¾…é‡è¯•çš„ä»»åŠ¡"""
        try:
            pending = self.failure_dao.get_pending_failures()
            for failure in pending:
                result = FetchResult(
                    source=failure.source,
                    success=False,
                    item_count=0,
                    error_message=failure.error_message,
                    timestamp=failure.last_try_at or datetime.now(),
                    retry_count=failure.retry_count,
                    status=FetchStatus.PENDING
                )
                # é‡æ–°åŠ å…¥é‡è¯•é˜Ÿåˆ—
                self.retry_manager.record_result(result)
            
            if pending:
                self.logger.info(f"åŠ è½½äº† {len(pending)} ä¸ªå¾…é‡è¯•çš„æ•°æ®æº")
        except Exception as e:
            self.logger.error(f"åŠ è½½å¾…é‡è¯•ä»»åŠ¡å¤±è´¥: {e}")

    def _setup_tasks(self):
        """è®¾ç½®é»˜è®¤ä»»åŠ¡"""
        # æ·»åŠ è·å–çƒ­ç‚¹ä»»åŠ¡
        self.add_task(
            name='fetch_trending',
            schedule=SCHEDULE['fetch_trending']['schedule'],
            task_func=self._fetch_all_trending,
            enabled=SCHEDULE['fetch_trending']['enabled']
        )

        # æ·»åŠ æ•°æ®æ¸…ç†ä»»åŠ¡
        self.add_task(
            name='cleanup_old_data',
            schedule='03:00',
            task_func=self._cleanup_old_data,
            enabled=True
        )

    def _run_scheduler(self):
        """è°ƒåº¦å™¨ä¸»å¾ªç¯ï¼ˆé›†æˆé‡è¯•é€»è¾‘ï¼‰"""
        self.logger.info("è°ƒåº¦å™¨å¼€å§‹è¿è¡Œï¼ˆé›†æˆé‡è¯•æœºåˆ¶ï¼‰...")

        while self.running and not self.stop_event.is_set():
            try:
                # 1. æ£€æŸ¥å¹¶æ‰§è¡Œå®šæ—¶ä»»åŠ¡
                for name, task in self.tasks.items():
                    if not task['enabled']:
                        continue

                    if self._should_run(task):
                        self.logger.info(f"æ‰§è¡Œä»»åŠ¡: {name}")
                        try:
                            task['func']()
                            task['last_run'] = datetime.now()
                        except Exception as e:
                            self.logger.error(f"ä»»åŠ¡ {name} æ‰§è¡Œå¤±è´¥: {e}")

                # 2. å¤„ç†é‡è¯•é˜Ÿåˆ—
                retry_results = self.retry_manager.process_retries()
                if retry_results:
                    # å¦‚æœæœ‰é‡è¯•æˆåŠŸçš„ï¼Œé‡æ–°ç”ŸæˆæŠ¥å‘Š
                    success_sources = [r.source for r in retry_results if r.success]
                    if success_sources:
                        self.logger.info(f"æ•°æ®æº {', '.join(success_sources)} é‡è¯•æˆåŠŸï¼Œé‡æ–°ç”ŸæˆæŠ¥å‘Š...")
                        self._generate_report()

                # 3. ç­‰å¾…ä¸€æ®µæ—¶é—´å†æ£€æŸ¥
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

            except Exception as e:
                self.logger.error(f"è°ƒåº¦å™¨è¿è¡Œé”™è¯¯: {e}")
                time.sleep(60)

        self.logger.info("è°ƒåº¦å™¨å·²åœæ­¢")

    def _fetch_all_trending(self):
        """è·å–æ‰€æœ‰çƒ­ç‚¹ä¿¡æ¯ï¼ˆé›†æˆé‡è¯•è®°å½•ï¼‰"""
        self.logger.info("=" * 60)
        self.logger.info("å¼€å§‹è·å–æ‰€æœ‰çƒ­ç‚¹ä¿¡æ¯...")

        all_items = []
        fetch_results = []

        # è·å–GitHubæ•°æ®
        if DATA_SOURCES.get('github', {}).get('enabled'):
            result = self._fetch_source('github', "ğŸ“ˆ è·å– GitHub Trending...")
            if result and result.success:
                all_items.extend(self._get_items_from_result(result))
            fetch_results.append(result)
            
            # è·å–GitHub AIæ•°æ®
            result_ai = self._fetch_source('github_ai', "ğŸ¤– è·å– GitHub AI...")
            if result_ai and result_ai.success:
                all_items.extend(self._get_items_from_result(result_ai))
            fetch_results.append(result_ai)

        # è·å–Bç«™æ•°æ®
        if DATA_SOURCES.get('bilibili', {}).get('enabled'):
            result = self._fetch_source('bilibili', "ğŸ¥ è·å– Bç«™çƒ­é—¨...")
            if result and result.success:
                all_items.extend(self._get_items_from_result(result))
            fetch_results.append(result)

        # è·å–arXivæ•°æ®
        if DATA_SOURCES.get('arxiv', {}).get('enabled'):
            result = self._fetch_source('arxiv', "ğŸ“š è·å– ArXivè®ºæ–‡...")
            if result and result.success:
                all_items.extend(self._get_items_from_result(result))
            fetch_results.append(result)
        
        # è·å–HackerNewsæ•°æ®
        if DATA_SOURCES.get('hackernews', {}).get('enabled'):
            result = self._fetch_source('hackernews', "ğŸ“° è·å– HackerNews...")
            if result and result.success:
                all_items.extend(self._get_items_from_result(result))
            fetch_results.append(result)
        
        # è·å–çŸ¥ä¹çƒ­æ¦œæ•°æ®
        if DATA_SOURCES.get('zhihu', {}).get('enabled'):
            result = self._fetch_source('zhihu', "ğŸ”¥ è·å– çŸ¥ä¹çƒ­æ¦œ...")
            if result and result.success:
                all_items.extend(self._get_items_from_result(result))
            fetch_results.append(result)
        
        # è·å–å¾®åšæ•°æ®
        if DATA_SOURCES.get('weibo', {}).get('enabled'):
            result = self._fetch_source('weibo', "ğŸ“± è·å– å¾®åšçƒ­æœ...")
            if result and result.success:
                all_items.extend(self._get_items_from_result(result))
            fetch_results.append(result)
        
        # è·å–æŠ–éŸ³æ•°æ®
        if DATA_SOURCES.get('douyin', {}).get('enabled'):
            result = self._fetch_source('douyin', "ğŸµ è·å– æŠ–éŸ³çƒ­æ¦œ...")
            if result and result.success:
                all_items.extend(self._get_items_from_result(result))
            fetch_results.append(result)

        # æå–å…³é”®è¯
        if all_items:
            self.logger.info("ğŸ” æå–å…³é”®è¯...")
            all_items = extract_keywords_for_items(all_items, top_k=5)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        if all_items:
            try:
                self.logger.info(f"ğŸ’¾ ä¿å­˜ {len(all_items)} æ¡æ•°æ®åˆ°æ•°æ®åº“...")
                saved_count = self.dao.refresh_items(all_items)
                self.logger.info(f"âœ… æˆåŠŸä¿å­˜ {saved_count} æ¡æ•°æ®")
            except Exception as e:
                self.logger.error(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")

        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()

        # è®°å½•è·å–ç»“æœåˆ°é‡è¯•ç®¡ç†å™¨
        for result in fetch_results:
            if result:
                self.retry_manager.record_result(result)

        self.logger.info(f"çƒ­ç‚¹ä¿¡æ¯è·å–å®Œæˆ! å…± {len(all_items)} æ¡")
        self.logger.info("=" * 60)

    def _fetch_source(self, source: str, message: str) -> Optional[FetchResult]:
        """è·å–å•ä¸ªæ•°æ®æºçš„æ•°æ®"""
        self.logger.info(message)
        
        try:
            fetcher = self.retry_manager._fetchers.get(source)
            if not fetcher:
                self.logger.warning(f"æ•°æ®æº {source} æœªæ³¨å†Œ")
                return None
            
            items = fetcher()
            
            result = FetchResult(
                source=source,
                success=len(items) > 0,
                item_count=len(items),
                error_message=None,
                timestamp=datetime.now(),
                retry_count=0,
                status=FetchStatus.SUCCESS
            )
            
            self.logger.info(f"âœ… {source} æ•°æ®è·å–å®Œæˆ: {len(items)} æ¡")
            return result
            
        except Exception as e:
            error_msg = str(e)
            self.logger.error(f"âŒ è·å– {source} æ•°æ®å¤±è´¥: {error_msg}")
            
            result = FetchResult(
                source=source,
                success=False,
                item_count=0,
                error_message=error_msg,
                timestamp=datetime.now(),
                retry_count=0,
                status=FetchStatus.PENDING
            )
            
            return result

    def _get_items_from_result(self, result: FetchResult) -> List:
        """ä»è·å–ç»“æœä¸­æå–æ•°æ®é¡¹ï¼ˆå®é™…è·å–æ•°æ®ï¼‰"""
        try:
            fetcher = self.retry_manager._fetchers.get(result.source)
            if fetcher:
                return fetcher()
        except Exception as e:
            self.logger.error(f"è·å– {result.source} æ•°æ®é¡¹å¤±è´¥: {e}")
        return []

    def _generate_report(self):
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        try:
            self.logger.info("ğŸ“„ ç”ŸæˆHTMLæŠ¥å‘Š...")
            generator = ReportGenerator(REPORTS_DIR)
            report_path = generator.generate_report()
            if report_path and report_path.exists():
                self.logger.info(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            else:
                self.logger.warning("âš ï¸  æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
        except Exception as e:
            self.logger.error(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")

    def refresh_data(self, sources: list = None):
        """
        åˆ·æ–°æŒ‡å®šæ•°æ®æºçš„æ•°æ®
        ç”¨äºæ‰‹åŠ¨åˆ·æ–°æˆ–ä¿®å¤æ•°æ®é—®é¢˜
        """
        self.logger.info("=" * 60)
        self.logger.info("å¼€å§‹åˆ·æ–°æ•°æ®...")

        all_items = []

        # å®šä¹‰æ‰€æœ‰å¯ç”¨çš„ fetcher
        fetchers = {
            'github': (GitHubTrendingFetcher, "ğŸ“ˆ åˆ·æ–° GitHub Trending...", 'fetch'),
            'github_ai': (GitHubTrendingFetcher, "ğŸ¤– åˆ·æ–° GitHub AI...", 'get_ai_repos'),
            'bilibili': (BilibiliHotFetcher, "ğŸ¥ åˆ·æ–° Bç«™çƒ­é—¨...", 'fetch'),
            'arxiv': (ArxivPapersFetcher, "ğŸ“š åˆ·æ–° ArXivè®ºæ–‡...", 'fetch'),
            'hackernews': (HackerNewsFetcher, "ğŸ“° åˆ·æ–° HackerNews...", 'fetch'),
            'zhihu': (ZhihuHotFetcher, "ğŸ”¥ åˆ·æ–° çŸ¥ä¹çƒ­æ¦œ...", 'fetch'),
            'weibo': (WeiboHotFetcher, "ğŸ“± åˆ·æ–° å¾®åšçƒ­æœ...", 'fetch'),
            'douyin': (DouyinHotFetcher, "ğŸµ åˆ·æ–° æŠ–éŸ³çƒ­æ¦œ...", 'fetch'),
        }

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°æ®æºï¼Œåˆ·æ–°æ‰€æœ‰å¯ç”¨çš„
        if sources is None:
            sources = [name for name, config in DATA_SOURCES.items() if config.get('enabled')]
            # æ·»åŠ  github_ai
            if 'github' in sources and 'github_ai' not in sources:
                sources.append('github_ai')

        for source in sources:
            if source not in fetchers:
                self.logger.warning(f"âš ï¸  æœªçŸ¥çš„æ•°æ®æº: {source}")
                continue

            fetcher_class, message, method_name = fetchers[source]

            # github_ai è·Ÿéš github çš„å¯ç”¨çŠ¶æ€
            if source == 'github_ai':
                if not DATA_SOURCES.get('github', {}).get('enabled'):
                    self.logger.info(f"â­ï¸  è·³è¿‡ {source} (GitHub æœªå¯ç”¨)")
                    continue
            elif not DATA_SOURCES.get(source, {}).get('enabled'):
                self.logger.info(f"â­ï¸  è·³è¿‡ {source} (æœªå¯ç”¨)")
                continue

            try:
                self.logger.info(message)
                fetcher = fetcher_class(logger=self.logger)
                # è°ƒç”¨æŒ‡å®šçš„æ–¹æ³•
                fetch_method = getattr(fetcher, method_name)
                items = fetch_method()
                all_items.extend(items)
                self.logger.info(f"âœ… {source} æ•°æ®åˆ·æ–°å®Œæˆ: {len(items)} æ¡")
                
                # æ ‡è®°ä¸ºæˆåŠŸ
                self.failure_dao.mark_success(source)
            except Exception as e:
                self.logger.error(f"âŒ åˆ·æ–° {source} æ•°æ®å¤±è´¥: {e}")

        # æå–å…³é”®è¯
        if all_items:
            self.logger.info("ğŸ” æå–å…³é”®è¯...")
            all_items = extract_keywords_for_items(all_items, top_k=5)

        # ä¿å­˜åˆ°æ•°æ®åº“
        if all_items:
            try:
                self.logger.info(f"ğŸ’¾ ä¿å­˜ {len(all_items)} æ¡æ•°æ®åˆ°æ•°æ®åº“...")
                saved_count = self.dao.refresh_items(all_items)
                self.logger.info(f"âœ… æˆåŠŸä¿å­˜ {saved_count} æ¡æ•°æ®")
            except Exception as e:
                self.logger.error(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")

        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()

        self.logger.info(f"æ•°æ®åˆ·æ–°å®Œæˆ! å…± {len(all_items)} æ¡")
        self.logger.info("=" * 60)

        return len(all_items)

    def get_fetch_status(self) -> Dict[str, Dict]:
        """
        è·å–æ‰€æœ‰æ•°æ®æºçš„çŠ¶æ€
        
        Returns:
            æ•°æ®æºçŠ¶æ€å­—å…¸
        """
        status = {}
        
        # è·å–é‡è¯•ç®¡ç†å™¨ä¸­çš„ç»“æœ
        results = self.retry_manager.get_all_results()
        
        for source in DATA_SOURCES.keys():
            if not DATA_SOURCES[source].get('enabled'):
                continue
                
            result = results.get(source)
            failure = self.failure_dao.get_by_source(source)
            
            if result:
                status[source] = {
                    'success': result.success,
                    'item_count': result.item_count,
                    'last_update': result.timestamp.isoformat(),
                    'error_message': result.error_message,
                    'retry_count': result.retry_count,
                    'status': result.status.value
                }
            elif failure:
                status[source] = {
                    'success': failure.status == 'success',
                    'item_count': 0,
                    'last_update': failure.last_try_at.isoformat() if failure.last_try_at else None,
                    'error_message': failure.error_message,
                    'retry_count': failure.retry_count,
                    'status': failure.status
                }
            else:
                status[source] = {
                    'success': False,
                    'item_count': 0,
                    'last_update': None,
                    'error_message': None,
                    'retry_count': 0,
                    'status': 'unknown'
                }
        
        return status

    def force_retry_source(self, source: str) -> bool:
        """
        å¼ºåˆ¶ç«‹å³é‡è¯•æŒ‡å®šæ•°æ®æº
        
        Args:
            source: æ•°æ®æºåç§°
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        self.logger.info(f"å¼ºåˆ¶é‡è¯•æ•°æ®æº: {source}")
        
        result = self.retry_manager.force_retry(source)
        
        if result and result.success:
            self.logger.info(f"âœ… {source} é‡è¯•æˆåŠŸï¼Œè·å– {result.item_count} æ¡æ•°æ®")
            # ä¿å­˜æ•°æ®
            try:
                items = self._get_items_from_result(result)
                if items:
                    self.dao.save_items(items)
                    self._generate_report()
                return True
            except Exception as e:
                self.logger.error(f"ä¿å­˜ {source} æ•°æ®å¤±è´¥: {e}")
                return False
        else:
            self.logger.error(f"âŒ {source} é‡è¯•å¤±è´¥")
            return False

    def _cleanup_old_data(self):
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        try:
            self.logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†è¿‡æœŸæ•°æ®...")
            days = DATABASE.get('cleanup_days', 30)
            deleted = self.dao.delete_old_data(days)
            self.logger.info(f"âœ… æ¸…ç†å®Œæˆ: åˆ é™¤ {deleted} æ¡è¿‡æœŸæ•°æ®")
            
            # æ¸…ç†æ—§çš„å¤±è´¥è®°å½•
            deleted_failures = self.failure_dao.delete_old_failures(days=7)
            self.logger.info(f"âœ… æ¸…ç†å®Œæˆ: åˆ é™¤ {deleted_failures} æ¡è¿‡æœŸå¤±è´¥è®°å½•")
        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç†æ•°æ®å¤±è´¥: {e}")
